import torch
import torch.backends
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm


from model import make_model
from data1 import load_and_process_data  # ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ë§Œ ê°€ì ¸ì˜¤ê¸°

# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì‹¤í–‰
train_data_loader, valid_data_loader, test_data_loader, en_vocab, de_vocab, pad_index = load_and_process_data()

print("âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
print(f"í›ˆë ¨ ë°ì´í„° ë°°ì¹˜ ê°œìˆ˜: {len(train_data_loader)}")
print(f"ê²€ì¦ ë°ì´í„° ë°°ì¹˜ ê°œìˆ˜: {len(valid_data_loader)}")
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ë°°ì¹˜ ê°œìˆ˜: {len(test_data_loader)}")
print(f"ì˜ì–´ ì–´íœ˜ ì‚¬ì „ í¬ê¸° : {len(en_vocab)}")
print(f"ë…ì¼ì–´ ì–´íœ˜ ì‚¬ì „ í¬ê¸° : {len(de_vocab)}\n")


# train.pyì—ì„œ ë°ì´í„° ë¡œë”© í›„, ì•„ë˜ ì½”ë“œ ì¶”ê°€
for batch in train_data_loader:
    print(f"ğŸ”¹ ë°°ì¹˜ í¬ê¸° (ì˜ì–´): {batch['en_ids'].shape}")
    print(f"ğŸ”¹ ë°°ì¹˜ í¬ê¸° (ë…ì¼ì–´): {batch['de_ids'].shape}")
    print(f"ğŸ”¹ ì˜ì–´ ë°ì´í„° ìƒ˜í”Œ: \n{batch['en_ids'][0]}")
    print(f"ğŸ”¹ ë…ì¼ì–´ ë°ì´í„° ìƒ˜í”Œ: \n{batch['de_ids'][0]}")
    break  # ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ í™•ì¸ í›„ ì¢…ë£Œ





# GPUì§€ì› ë° ëª¨ë¸ ìƒì„±
if torch.backends.mps.is_available():
    device = torch.device("mps")  # Metal Performance Shaders (Apple GPU)
    print("Using MPS (Metal Performance Shaders)")
else:
    device = torch.device("cpu")  # CPUë§Œ ì‚¬ìš©
    print("Using CPU")
source_vocab_size = len(en_vocab)  
target_vocab_size = len(de_vocab)  

model = make_model(source_vocab_size, target_vocab_size).to(device)



# maskingí•¨ìˆ˜ ìƒì„± (encoder self attention)
def create_src_mask(src, pad_idx):
    # src: [batch_size, src_len]
    # íŒ¨ë”©ì´ ì•„ë‹Œ ìœ„ì¹˜ë¥¼ Trueë¡œ ë§Œë“¤ì–´ [batch_size, 1, 1, src_len] í˜•íƒœì˜ ë§ˆìŠ¤í¬ë¥¼ ìƒì„±
    return (src != pad_idx).unsqueeze(dim=1).unsqueeze(dim=2)


# maskingí•¨ìˆ˜ ìƒì„± (decoder masked self attention)
def create_trg_mask(trg, pad_idx):
    # trg: [batch_size, trg_len]
    trg_mask = (trg != pad_idx).unsqueeze(dim=1).unsqueeze(dim=2)
    # trg_mask: [batch_size, 1, 1, trg_len]
    seq_len = trg.size(1)
    # ì´í›„ í† í°ì„ ë§‰ê¸° ìœ„í•œ subsequent mask: ìƒì‚¼ê° í–‰ë ¬
    subsequent_mask = torch.triu(torch.ones((1, 1, seq_len, seq_len), device=trg.device), diagonal=1).bool()
    # ë‘ ë§ˆìŠ¤í¬ë¥¼ ê²°í•©
    return trg_mask & ~subsequent_mask



# ì†ì‹¤ í•¨ìˆ˜ ì •ì˜ (pad_indexëŠ” ë¹¼ê³  í•™ìŠµ)
criterion = nn.CrossEntropyLoss(ignore_index=pad_index)


# ì˜µí‹°ë§ˆì´ì € ì„¤ì •
optimizer = optim.Adam(model.parameters(), lr=0.0005, betas=(0.9, 0.98), eps=1e-9)


# í•™ìŠµ ë£¨í”„ ì„¤ì •
def train_epoch(model, data_loader, optimizer, criterion, device, pad_idx):
    model.train()
    epoch_loss = 0
    
    # tqdm progress barë¡œ ë°°ì¹˜ ë°˜ë³µ
    for batch in tqdm(data_loader, desc="Training", leave=False):
        src = batch["en_ids"].to(device)
        trg = batch["de_ids"].to(device)
        
        optimizer.zero_grad()

        src_mask = create_src_mask(src, pad_idx)
        trg_mask = create_trg_mask(trg[:, :-1], pad_idx)
        
        # target ë¬¸ì¥ì—ì„œ ë§ˆì§€ë§‰ í† í° ì œì™¸í•˜ì—¬ ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš©
        output = model(src, trg[:, :-1], src_mask, trg_mask)
        
        output_dim = output.shape[-1]
        output = output.contiguous().view(-1, output_dim)
        trg = trg[:, 1:].contiguous().view(-1)
        
        loss = criterion(output, trg)
        loss.backward()
        optimizer.step()
        
        epoch_loss += loss.item()
    
    return epoch_loss / len(data_loader)

def evaluate(model, data_loader, criterion, device, pad_idx):
    model.eval()
    epoch_loss = 0
    
    with torch.no_grad():
        for batch in tqdm(data_loader, desc="Evaluating", leave=False):
            src = batch["en_ids"].to(device)
            trg = batch["de_ids"].to(device)

            src_mask = create_src_mask(src, pad_idx)
            trg_mask = create_trg_mask(trg[:, :-1], pad_idx)
            
            output = model(src, trg[:, :-1], src_mask, trg_mask)
            
            output_dim = output.shape[-1]
            output = output.contiguous().view(-1, output_dim)
            trg = trg[:, 1:].contiguous().view(-1)
            
            loss = criterion(output, trg)
            epoch_loss += loss.item()
    
    return epoch_loss / len(data_loader)



def train_model(model, train_loader, valid_loader, optimizer, criterion, device, pad_idx, n_epochs=10):
    for epoch in range(n_epochs):
        train_loss = train_epoch(model, train_loader, optimizer, criterion, device, pad_idx)
        valid_loss = evaluate(model, valid_loader, criterion, device, pad_idx)
        print(f"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}")
    
    # ëª¨ë¸ ì €ì¥
    torch.save(model.state_dict(), "new_transformer_model.pth")
    print("ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")




###########################################



if __name__ == "__main__":
    train_model(model, train_data_loader, valid_data_loader, optimizer, criterion, device, pad_index)


